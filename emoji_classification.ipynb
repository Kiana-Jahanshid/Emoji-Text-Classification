{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aBlHPpuh4nzK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "88z7x2454nzM"
      },
      "outputs": [],
      "source": [
        "def read_csv_method(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    sentence = np.array( df[\"sentence\"] ) # X\n",
        "    label = np.array( df[\"label\"] , dtype=int) # Y\n",
        "    return sentence , label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xkt7azTs4nzM"
      },
      "outputs": [],
      "source": [
        "X_train , Y_train = read_csv_method(\"train.csv\")\n",
        "X_test , Y_test = read_csv_method(\"test.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae0razVk4nzN",
        "outputId": "0c5750b5-57de-4240-bc01-e2b230c10482"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['never talk to me again', 'I am proud of your achievements',\n",
              "       'It is the worst day in my life', 'Miss you so much',\n",
              "       'food is life', 'I love you mum', 'Stop saying bullshit',\n",
              "       'congratulations on your acceptance',\n",
              "       'The assignment is too long ', 'I want to go play',\n",
              "       'she did not answer my text ', 'Your stupidity has no limit',\n",
              "       'how many points did he score', 'my algorithm performs poorly',\n",
              "       'I got approved', 'Stop shouting at me',\n",
              "       'Sounds like a fun plan ha ha', 'no one likes him',\n",
              "       'the game just finished', 'I will celebrate soon',\n",
              "       'So sad you are not coming', 'She is my dearest love', 'Good job',\n",
              "       'It was funny lol', 'candy is life ', 'The chicago cubs won again',\n",
              "       'I am hungry', 'I am so excited to see you after so long',\n",
              "       'you did well on you exam', 'lets brunch some day',\n",
              "       'he is so cute', 'How dare you ask that',\n",
              "       'do you want to join me for dinner ', 'I said yes',\n",
              "       'she is attractive', 'you suck', 'she smiles a lot',\n",
              "       'he is laughing', 'she takes forever to get ready ',\n",
              "       'French macaroon is so tasty', 'we made it', 'I am excited',\n",
              "       'I adore my dogs', 'Congratulations', 'this girl was mean',\n",
              "       'you two are cute',\n",
              "       'my code is working but the grader gave me zero',\n",
              "       'this joke is killing me haha', 'do you like pizza ',\n",
              "       'you got a down grade', 'I missed you',\n",
              "       'I think I will end up alone', 'I got humiliated by my sister',\n",
              "       'you are awful', 'I cooked meat', 'This is so funny',\n",
              "       'lets exercise', 'he is the best player',\n",
              "       'I am going to the stadium',\n",
              "       'You are incredibly intelligent and talented',\n",
              "       'Stop shouting at me', 'Who is your favorite player',\n",
              "       'I like you a lot', 'i miss him', 'my dog just had a few puppies',\n",
              "       'I hate him', 'I want chinese food', 'cookies are good',\n",
              "       'her smile is so charming',\n",
              "       'Bravo for the announcement it got a lot of traction',\n",
              "       'she plays baseball', 'he did an amazing job',\n",
              "       'The baby is adorable', 'I was waiting for her for two hours ',\n",
              "       'funny', 'I like it when people smile', 'I love dogs',\n",
              "       'they are so kind and friendly',\n",
              "       'So bad that you cannot come with us', 'he likes baseball',\n",
              "       'I am so impressed by your dedication to this project',\n",
              "       'I am at the baseball game', 'Bravo', 'What a fun moment',\n",
              "       'I want to have sushi for dinner', 'I am very disappointed',\n",
              "       'he can not do anything', 'lol', 'Lets have food together',\n",
              "       'she is so cute', 'miss you my dear', 'I am looking for a date',\n",
              "       'I am frustrated', 'I lost my wallet', 'you failed the midterm',\n",
              "       'ha ha ha it was so funny', 'Do you want to give me a hug',\n",
              "       'who is playing in the final', 'she is happy',\n",
              "       'You are not qualified for this position', 'I love my dad',\n",
              "       'this guy was such a joke', 'Good joke',\n",
              "       'This specialization is great', 'you could not solve it',\n",
              "       'I am so happy for you', 'Congrats on the new job',\n",
              "       'I am proud of you forever', 'I want to eat',\n",
              "       'That catcher sucks ', 'The first base man got the ball',\n",
              "       'this is bad', 'you did not do your homework',\n",
              "       'I will have a cheese cake', 'do you have a ball',\n",
              "       'the lectures are great though ',\n",
              "       'Are you down for baseball this afternoon',\n",
              "       'what are the rules of the game', 'I am always working',\n",
              "       'where is the stadium',\n",
              "       'She is the cutest person I have ever seen',\n",
              "       'vegetables are healthy', 'he is handsome',\n",
              "       'too bad that you were not here', 'you are a loser',\n",
              "       'I love indian food', 'Who is down for a restaurant',\n",
              "       'he had to make a home run', 'I am ordering food',\n",
              "       'What is wrong with you', 'I love you', 'great job'], dtype=object)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfZ-VDWX4nzN",
        "outputId": "3de1f422-4377-4803-d01b-a89e627db245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 2, 3, 0, 4, 0, 3, 2, 3, 1, 3, 3, 1, 3, 2, 3, 2, 3, 1, 2, 3, 0,\n",
              "       2, 2, 2, 1, 4, 2, 2, 4, 0, 3, 4, 2, 0, 3, 2, 2, 3, 4, 2, 2, 0, 2,\n",
              "       3, 0, 3, 2, 4, 3, 0, 3, 3, 3, 4, 2, 1, 1, 1, 2, 3, 1, 0, 0, 0, 3,\n",
              "       4, 4, 2, 2, 1, 2, 0, 3, 2, 2, 0, 0, 3, 1, 2, 1, 2, 2, 4, 3, 3, 2,\n",
              "       4, 0, 0, 0, 3, 3, 3, 2, 0, 1, 2, 3, 0, 2, 2, 2, 3, 2, 2, 2, 4, 1,\n",
              "       1, 3, 3, 4, 1, 2, 1, 1, 3, 1, 0, 4, 0, 3, 3, 4, 4, 1, 4, 3, 0, 2])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pnCJ1QP4nzN",
        "outputId": "812dcc17-b6a6-4bc3-e305-6c10edadcce5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('I love you mum', 0)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[5] , Y_train[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iadjnSdG4nzN",
        "outputId": "dcc761fd-56bd-422c-c632-8f6f8d0b01c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('I want to go play', 1)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[9] , Y_train[9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_cVkI254nzN",
        "outputId": "e2984750-4622-43fc-a2db-954550c42263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ’š\n",
            "ðŸ€\n",
            "ðŸ˜„\n",
            "ðŸ˜ž\n",
            "ðŸ½\n"
          ]
        }
      ],
      "source": [
        "def label_to_emoji(label):\n",
        "    emojies = [\"ðŸ’š\" , \"ðŸ€\" , \"ðŸ˜„\" , \"ðŸ˜ž\" , \"ðŸ½\"]\n",
        "    return emojies[label]\n",
        "\n",
        "print(label_to_emoji(0))\n",
        "print(label_to_emoji(1))\n",
        "print(label_to_emoji(2))\n",
        "print(label_to_emoji(3))\n",
        "print(label_to_emoji(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3kwE0Ee4nzT",
        "outputId": "144a69a7-3fc3-4821-a809-40838434cd8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('I love you mum', 'ðŸ’š')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[5] , label_to_emoji(Y_train[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZGK0jAi4nzT",
        "outputId": "8080c4b9-4bf2-41be-958e-9110641cb84d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4]\n",
            "[22 19 38 36 17]\n"
          ]
        }
      ],
      "source": [
        "unique , counts = np.unique(Y_train , return_counts=True)\n",
        "print(unique)\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qq4dM3xV4nzU",
        "outputId": "cefe313f-170d-415d-a523-5fc374963995"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I am so impressed by your dedication to this project'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(X_train , key=len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy0EU2tC4nzU",
        "outputId": "dd36caae-3c65-4bc4-d3b9-287e004d5dce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(max(X_train , key=len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsYeC67g4nzU",
        "outputId": "9bd4d6e2-1bb5-4e0d-e53c-7df9ec753c33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I',\n",
              " 'am',\n",
              " 'so',\n",
              " 'impressed',\n",
              " 'by',\n",
              " 'your',\n",
              " 'dedication',\n",
              " 'to',\n",
              " 'this',\n",
              " 'project']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(X_train , key=len).split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDxlkhOg4nzU",
        "outputId": "e11b8798-11d3-4cc4-8d69-56a48fb6f520"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_sentence_len = len(max(X_train , key=len).split(\" \"))\n",
        "max_sentence_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4llVM3Uy4nzU",
        "outputId": "a8a3cc6b-f040-4e20-ff01-7750df13a699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-15 13:59:35--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-01-15 13:59:36--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: â€˜glove.6B.zipâ€™\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2024-01-15 14:02:15 (5.17 MB/s) - â€˜glove.6B.zipâ€™ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "# OR :\n",
        "# import requests\n",
        "# url = r'https://nlp.stanford.edu/data/glove.6B.zip'\n",
        "# output = r'./glove.6B.zip'\n",
        "# r = requests.get(url)\n",
        "# with open(output, 'wb') as f:\n",
        "#     f.write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IW0zvMca4nzU"
      },
      "outputs": [],
      "source": [
        "!unzip -q glove.6B.zip -d glove.6B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Ieom-0Fitq"
      },
      "source": [
        "### the dictionary we want to create :\n",
        "{\n",
        "\"hello\" : [ 0.46529 , -0.22325 , -0.49207 ,  0.33727 , ... ] , <br/>\n",
        "  \"book\" : [-1.0178  ,  0.68267 , -0.20788 , -0.73393 ,  1.2597  ... ] , <br/>\n",
        "  ....\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zclEXL416o5g",
        "outputId": "a94adc23-c178-4e00-dbe8-d7870f6d0b39"
      },
      "outputs": [],
      "source": [
        "text_file = open(\"/content/glove.6B/glove.6B.50d.txt\" , encoding=\"utf-8\")\n",
        "\n",
        "word_vectors = {}\n",
        "for line in text_file :\n",
        "  line = line.strip().split()\n",
        "  print(line)\n",
        "  word = line[0]\n",
        "  #print(word)\n",
        "  vector = np.array(line[1:] , dtype=np.float64)\n",
        "  #print(vector)\n",
        "  word_vectors[word] = vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7rqXRONErXc",
        "outputId": "0eeb5b8a-e50e-4eb0-d14f-3d938ac81704"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.49251 , -0.24279 , -0.49748 ,  0.28443 ,  0.16984 ,  0.61016 ,\n",
              "        0.20294 , -0.19734 ,  0.93474 , -0.11809 , -0.26342 ,  0.97142 ,\n",
              "        1.0427  ,  0.60017 , -0.46936 ,  0.10087 ,  0.60649 ,  1.1277  ,\n",
              "       -1.1823  , -0.29334 , -0.72885 , -0.46904 ,  1.1104  ,  0.27504 ,\n",
              "        0.48043 , -1.3031  , -0.58713 ,  0.90264 ,  0.089552, -0.60348 ,\n",
              "        1.1117  , -0.85367 , -0.13902 ,  0.87767 , -0.19307 ,  0.10299 ,\n",
              "       -0.83688 , -0.87202 ,  0.46529 , -0.22325 , -0.49207 ,  0.33727 ,\n",
              "       -0.49699 ,  0.95006 ,  0.75007 , -0.21252 ,  0.47244 , -1.4552  ,\n",
              "        0.11704 , -0.61483 ])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_vectors[\"snake\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5FWZt9iExb3",
        "outputId": "1683ab99-7099-4f1b-fc57-226c8fd37781"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.18997  ,  0.11493  ,  0.85566  , -0.039811 ,  0.10742  ,\n",
              "       -0.44042  ,  1.2496   ,  0.49928  ,  0.58689  ,  0.8321   ,\n",
              "        0.027948 , -0.85445  , -0.39854  , -0.18763  , -0.050099 ,\n",
              "        0.95036  ,  0.59861  ,  0.25454  ,  0.6548   ,  0.87505  ,\n",
              "        0.82139  , -0.0041283,  0.9193   , -0.033385 ,  0.1914   ,\n",
              "       -3.0393   ,  0.58703  ,  0.23673  ,  0.031058 ,  0.17775  ,\n",
              "        2.4503   , -0.35655  , -0.68777  , -0.43984  ,  0.12271  ,\n",
              "       -0.46345  , -0.29642  ,  0.33648  , -1.6442   ,  0.23183  ,\n",
              "       -0.019779 ,  0.0057172,  0.94701  , -1.2708   ,  0.53767  ,\n",
              "        0.80297  , -0.70422  ,  1.7059   , -0.64729  , -0.97299  ])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_vectors[\"iran\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ifCYFvdE3kJ",
        "outputId": "a4910e9b-dbf2-4fcc-e550-f8a287c72cb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.5897  , -0.55043 , -1.0106  ,  0.41226 ,  0.57348 ,  0.23464 ,\n",
              "       -0.35773 , -1.78    ,  0.10745 ,  0.74913 ,  0.45013 ,  1.0351  ,\n",
              "        0.48348 ,  0.47954 ,  0.51908 , -0.15053 ,  0.32474 ,  1.0789  ,\n",
              "       -0.90894 ,  0.42943 , -0.56388 ,  0.69961 ,  0.13501 ,  0.16557 ,\n",
              "       -0.063592,  0.35435 ,  0.42819 ,  0.1536  , -0.47018 , -1.0935  ,\n",
              "        1.361   , -0.80821 , -0.674   ,  1.2606  ,  0.29554 ,  1.0835  ,\n",
              "        0.2444  , -1.1877  , -0.60203 , -0.068315,  0.66256 ,  0.45336 ,\n",
              "       -1.0178  ,  0.68267 , -0.20788 , -0.73393 ,  1.2597  ,  0.15425 ,\n",
              "       -0.93256 , -0.15025 ])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_vectors[\"python\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9CCu5pzFFwk",
        "outputId": "99362d5d-7612-45e6-bd5e-ba947e5657cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.031918, -0.44988 ,  0.2117  , -0.24515 , -0.55618 ,  0.72347 ,\n",
              "        0.43707 ,  0.39521 ,  0.35605 , -0.50786 , -0.50423 , -0.1079  ,\n",
              "       -0.14377 , -0.25872 , -0.18964 , -0.14668 , -0.22247 ,  0.34439 ,\n",
              "        0.69779 , -0.42618 , -0.61677 ,  0.83128 , -0.23124 , -0.060008,\n",
              "        0.93573 ,  0.67213 , -0.28688 ,  0.28456 , -0.45824 ,  0.17432 ,\n",
              "       -1.54    ,  0.42625 ,  0.12369 ,  0.73562 , -0.17367 ,  0.12393 ,\n",
              "       -0.073008,  0.056451,  0.47745 , -0.28937 ,  0.63418 ,  0.38361 ,\n",
              "       -0.50057 , -0.027956, -0.53396 ,  0.047757,  0.43252 ,  0.21063 ,\n",
              "       -0.15044 ,  0.48666 ])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_vectors[\"kiana\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGZ6x4dnFSD1",
        "outputId": "552025ce-4ae8-4470-89a0-f16c4ad5cb17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word_vectors[\"you\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq-gNyCmvqAK"
      },
      "source": [
        "# length of all word's feature vectors , in glove.6B.50d.txt is equal to 50 ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30EfuK_kIz-z"
      },
      "source": [
        "### Each word , has it's own feature vector\n",
        "\n",
        "<br/>\n",
        "\n",
        "# Question :    \n",
        "how to feed a sentence with many words , into a network ?\n",
        "<br/>\n",
        "or\n",
        "<br/>\n",
        "### how to feed many feature vectors with  length of 50 , into our network ?\n",
        "\n",
        "<br/>\n",
        "\n",
        "1st idea : concat these FV's :    \n",
        "## problem :  \n",
        "here we have a Fvector of lenght 150 (for a sentence with 3 words) , THERFORE we have to consider 150 neurons in input layers . <br/>\n",
        "which is not compatible with other sentence's length .\n",
        "and this network only works with sentences with 3 words .\n",
        "\n",
        "<br/>\n",
        "\n",
        "# solution  :  \n",
        "take MEAN(average) of all N Feature vectors .\n",
        "so the result's length will be 50 .\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVpbnp9l7qGi"
      },
      "source": [
        "we implement this idea on our X_train data :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "806RWRnR9G6J",
        "outputId": "617de856-0e7f-49b7-9717-b567f6d8ff8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.15917333, -0.10315333, -0.346679  , -0.46174667,  0.49464   ,\n",
              "        0.10710667, -0.26262   , -0.03155247,  0.05453667,  0.12203586,\n",
              "       -0.22185333,  0.54613   ,  0.19048333, -0.14560667,  0.90449   ,\n",
              "        0.0391347 ,  0.56057   ,  0.11737533, -0.335168  , -0.56153   ,\n",
              "       -0.40509   , -0.04400667,  1.00475   ,  0.51751   ,  0.67369667,\n",
              "       -1.72456   , -0.63001   ,  0.241895  ,  1.16233333, -0.96878   ,\n",
              "        2.5002    ,  0.35573667, -0.24802333, -0.09538333, -0.54016967,\n",
              "       -0.13841   , -0.03611667, -0.07173667,  0.31141   , -0.10284333,\n",
              "       -0.09298877,  0.00746733,  0.31971   ,  0.51315333,  0.69481533,\n",
              "        0.30034   , -0.24001667, -0.51085333, -0.051172  ,  0.50552   ])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# first he have to convert uppercase alphabets in X_train words\n",
        "\n",
        "def sentence_to_average(sentence):\n",
        "  sentence= sentence.lower()\n",
        "  words = sentence.strip().split(\" \")\n",
        "\n",
        "  sum_vectors = np.zeros((50,))\n",
        "  for word in words :\n",
        "      sum_vectors += word_vectors[word]\n",
        "\n",
        "  avg_vector = sum_vectors / len(words)\n",
        "  return avg_vector\n",
        "\n",
        "\n",
        "sentence_to_average(\"i hate fish\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2gAYx-Y63h7",
        "outputId": "c7c0240d-7026-4df8-f1d7-82282bab73e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(132, 50)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_avg = []\n",
        "for x_train in X_train :\n",
        "  X_train_avg.append(sentence_to_average(x_train))\n",
        "\n",
        "X_train_avg = np.array(X_train_avg)\n",
        "X_train_avg.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plj5QpxmfWz4",
        "outputId": "329bd295-30ce-4053-cbe1-f9adff4cb463"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 2, 3, 0, 4, 0, 3, 2, 3, 1, 3, 3, 1, 3, 2, 3, 2, 3, 1, 2, 3, 0,\n",
              "       2, 2, 2, 1, 4, 2, 2, 4, 0, 3, 4, 2, 0, 3, 2, 2, 3, 4, 2, 2, 0, 2,\n",
              "       3, 0, 3, 2, 4, 3, 0, 3, 3, 3, 4, 2, 1, 1, 1, 2, 3, 1, 0, 0, 0, 3,\n",
              "       4, 4, 2, 2, 1, 2, 0, 3, 2, 2, 0, 0, 3, 1, 2, 1, 2, 2, 4, 3, 3, 2,\n",
              "       4, 0, 0, 0, 3, 3, 3, 2, 0, 1, 2, 3, 0, 2, 2, 2, 3, 2, 2, 2, 4, 1,\n",
              "       1, 3, 3, 4, 1, 2, 1, 1, 3, 1, 0, 4, 0, 3, 3, 4, 4, 1, 4, 3, 0, 2])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWfnFmPfe4IF",
        "outputId": "e0990492-209a-495a-b4cf-5d28b3f1efd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we have 5 neurons in last layer of network\n",
        "\n",
        "# we should one-hot Y outputs\n",
        "Y_train_OneHot = tf.keras.utils.to_categorical(Y_train , num_classes=5)\n",
        "Y_train_OneHot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d17p8CWwfj-I"
      },
      "source": [
        "# TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHpXKH9lfir7",
        "outputId": "d8137182-c53a-41ac-d7e6-4709b87b6245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9347 - accuracy: 0.1894\n",
            "Epoch 2/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8895 - accuracy: 0.1894\n",
            "Epoch 3/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8505 - accuracy: 0.2045\n",
            "Epoch 4/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.8097 - accuracy: 0.1970\n",
            "Epoch 5/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7723 - accuracy: 0.2197\n",
            "Epoch 6/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7369 - accuracy: 0.2424\n",
            "Epoch 7/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7083 - accuracy: 0.2273\n",
            "Epoch 8/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6802 - accuracy: 0.2197\n",
            "Epoch 9/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6531 - accuracy: 0.2424\n",
            "Epoch 10/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6285 - accuracy: 0.2652\n",
            "Epoch 11/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6055 - accuracy: 0.2803\n",
            "Epoch 12/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5845 - accuracy: 0.2879\n",
            "Epoch 13/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5654 - accuracy: 0.3030\n",
            "Epoch 14/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5498 - accuracy: 0.3030\n",
            "Epoch 15/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5359 - accuracy: 0.3182\n",
            "Epoch 16/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5224 - accuracy: 0.3258\n",
            "Epoch 17/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5113 - accuracy: 0.3333\n",
            "Epoch 18/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5000 - accuracy: 0.3258\n",
            "Epoch 19/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4896 - accuracy: 0.3182\n",
            "Epoch 20/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4796 - accuracy: 0.3182\n",
            "Epoch 21/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4706 - accuracy: 0.3333\n",
            "Epoch 22/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4619 - accuracy: 0.3636\n",
            "Epoch 23/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4526 - accuracy: 0.3864\n",
            "Epoch 24/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4445 - accuracy: 0.3636\n",
            "Epoch 25/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4360 - accuracy: 0.3636\n",
            "Epoch 26/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4291 - accuracy: 0.3712\n",
            "Epoch 27/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4210 - accuracy: 0.3788\n",
            "Epoch 28/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4134 - accuracy: 0.3939\n",
            "Epoch 29/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4065 - accuracy: 0.3939\n",
            "Epoch 30/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3980 - accuracy: 0.4015\n",
            "Epoch 31/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3903 - accuracy: 0.4091\n",
            "Epoch 32/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3830 - accuracy: 0.4167\n",
            "Epoch 33/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3752 - accuracy: 0.4318\n",
            "Epoch 34/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3681 - accuracy: 0.4394\n",
            "Epoch 35/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3607 - accuracy: 0.4470\n",
            "Epoch 36/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3540 - accuracy: 0.4318\n",
            "Epoch 37/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3474 - accuracy: 0.4394\n",
            "Epoch 38/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3406 - accuracy: 0.4470\n",
            "Epoch 39/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3348 - accuracy: 0.4470\n",
            "Epoch 40/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3279 - accuracy: 0.4545\n",
            "Epoch 41/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3213 - accuracy: 0.4545\n",
            "Epoch 42/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3139 - accuracy: 0.4848\n",
            "Epoch 43/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3072 - accuracy: 0.5000\n",
            "Epoch 44/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3008 - accuracy: 0.5000\n",
            "Epoch 45/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2945 - accuracy: 0.5152\n",
            "Epoch 46/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2884 - accuracy: 0.5152\n",
            "Epoch 47/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2823 - accuracy: 0.5227\n",
            "Epoch 48/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2759 - accuracy: 0.5227\n",
            "Epoch 49/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2699 - accuracy: 0.5303\n",
            "Epoch 50/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2642 - accuracy: 0.5379\n",
            "Epoch 51/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2582 - accuracy: 0.5455\n",
            "Epoch 52/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2517 - accuracy: 0.5455\n",
            "Epoch 53/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2461 - accuracy: 0.5379\n",
            "Epoch 54/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2404 - accuracy: 0.5379\n",
            "Epoch 55/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2349 - accuracy: 0.5379\n",
            "Epoch 56/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2291 - accuracy: 0.5379\n",
            "Epoch 57/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2233 - accuracy: 0.5455\n",
            "Epoch 58/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2175 - accuracy: 0.5455\n",
            "Epoch 59/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2123 - accuracy: 0.5530\n",
            "Epoch 60/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2068 - accuracy: 0.5606\n",
            "Epoch 61/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2011 - accuracy: 0.5682\n",
            "Epoch 62/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1954 - accuracy: 0.5682\n",
            "Epoch 63/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1905 - accuracy: 0.5682\n",
            "Epoch 64/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1849 - accuracy: 0.5682\n",
            "Epoch 65/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1789 - accuracy: 0.5833\n",
            "Epoch 66/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1751 - accuracy: 0.5909\n",
            "Epoch 67/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1693 - accuracy: 0.5985\n",
            "Epoch 68/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1648 - accuracy: 0.5909\n",
            "Epoch 69/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1598 - accuracy: 0.5985\n",
            "Epoch 70/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1545 - accuracy: 0.5985\n",
            "Epoch 71/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1493 - accuracy: 0.5985\n",
            "Epoch 72/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1443 - accuracy: 0.6136\n",
            "Epoch 73/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1396 - accuracy: 0.6136\n",
            "Epoch 74/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1354 - accuracy: 0.6212\n",
            "Epoch 75/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1306 - accuracy: 0.6212\n",
            "Epoch 76/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1255 - accuracy: 0.6212\n",
            "Epoch 77/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1217 - accuracy: 0.6212\n",
            "Epoch 78/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1172 - accuracy: 0.6288\n",
            "Epoch 79/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1131 - accuracy: 0.6364\n",
            "Epoch 80/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1090 - accuracy: 0.6439\n",
            "Epoch 81/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1053 - accuracy: 0.6439\n",
            "Epoch 82/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1001 - accuracy: 0.6439\n",
            "Epoch 83/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0959 - accuracy: 0.6591\n",
            "Epoch 84/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0915 - accuracy: 0.6667\n",
            "Epoch 85/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0874 - accuracy: 0.6742\n",
            "Epoch 86/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0842 - accuracy: 0.6742\n",
            "Epoch 87/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0801 - accuracy: 0.6894\n",
            "Epoch 88/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0766 - accuracy: 0.6894\n",
            "Epoch 89/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0727 - accuracy: 0.6818\n",
            "Epoch 90/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0689 - accuracy: 0.6970\n",
            "Epoch 91/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0660 - accuracy: 0.6894\n",
            "Epoch 92/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0610 - accuracy: 0.6970\n",
            "Epoch 93/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0572 - accuracy: 0.7045\n",
            "Epoch 94/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0533 - accuracy: 0.7045\n",
            "Epoch 95/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0494 - accuracy: 0.7197\n",
            "Epoch 96/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0454 - accuracy: 0.7273\n",
            "Epoch 97/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0415 - accuracy: 0.7197\n",
            "Epoch 98/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0376 - accuracy: 0.7273\n",
            "Epoch 99/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0348 - accuracy: 0.7197\n",
            "Epoch 100/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0306 - accuracy: 0.7197\n",
            "Epoch 101/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0273 - accuracy: 0.7197\n",
            "Epoch 102/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0241 - accuracy: 0.7197\n",
            "Epoch 103/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0205 - accuracy: 0.7197\n",
            "Epoch 104/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0169 - accuracy: 0.7273\n",
            "Epoch 105/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0134 - accuracy: 0.7197\n",
            "Epoch 106/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0099 - accuracy: 0.7197\n",
            "Epoch 107/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0069 - accuracy: 0.7197\n",
            "Epoch 108/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0032 - accuracy: 0.7197\n",
            "Epoch 109/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9994 - accuracy: 0.7197\n",
            "Epoch 110/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9960 - accuracy: 0.7197\n",
            "Epoch 111/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9930 - accuracy: 0.7273\n",
            "Epoch 112/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9894 - accuracy: 0.7273\n",
            "Epoch 113/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9862 - accuracy: 0.7197\n",
            "Epoch 114/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9830 - accuracy: 0.7197\n",
            "Epoch 115/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9793 - accuracy: 0.7273\n",
            "Epoch 116/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9761 - accuracy: 0.7197\n",
            "Epoch 117/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9732 - accuracy: 0.7197\n",
            "Epoch 118/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9700 - accuracy: 0.7197\n",
            "Epoch 119/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9669 - accuracy: 0.7197\n",
            "Epoch 120/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9638 - accuracy: 0.7197\n",
            "Epoch 121/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9611 - accuracy: 0.7197\n",
            "Epoch 122/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9586 - accuracy: 0.7348\n",
            "Epoch 123/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9551 - accuracy: 0.7273\n",
            "Epoch 124/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9521 - accuracy: 0.7348\n",
            "Epoch 125/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9491 - accuracy: 0.7348\n",
            "Epoch 126/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9465 - accuracy: 0.7348\n",
            "Epoch 127/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9435 - accuracy: 0.7348\n",
            "Epoch 128/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9409 - accuracy: 0.7348\n",
            "Epoch 129/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9382 - accuracy: 0.7348\n",
            "Epoch 130/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9352 - accuracy: 0.7348\n",
            "Epoch 131/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9321 - accuracy: 0.7424\n",
            "Epoch 132/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9296 - accuracy: 0.7424\n",
            "Epoch 133/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9267 - accuracy: 0.7424\n",
            "Epoch 134/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9239 - accuracy: 0.7424\n",
            "Epoch 135/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9211 - accuracy: 0.7424\n",
            "Epoch 136/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9189 - accuracy: 0.7424\n",
            "Epoch 137/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9160 - accuracy: 0.7424\n",
            "Epoch 138/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9132 - accuracy: 0.7500\n",
            "Epoch 139/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9102 - accuracy: 0.7424\n",
            "Epoch 140/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9080 - accuracy: 0.7197\n",
            "Epoch 141/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9058 - accuracy: 0.7273\n",
            "Epoch 142/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9032 - accuracy: 0.7273\n",
            "Epoch 143/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9005 - accuracy: 0.7273\n",
            "Epoch 144/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8982 - accuracy: 0.7424\n",
            "Epoch 145/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8956 - accuracy: 0.7424\n",
            "Epoch 146/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8938 - accuracy: 0.7348\n",
            "Epoch 147/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8906 - accuracy: 0.7348\n",
            "Epoch 148/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8881 - accuracy: 0.7500\n",
            "Epoch 149/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8858 - accuracy: 0.7500\n",
            "Epoch 150/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8835 - accuracy: 0.7424\n",
            "Epoch 151/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8806 - accuracy: 0.7500\n",
            "Epoch 152/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8786 - accuracy: 0.7424\n",
            "Epoch 153/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8759 - accuracy: 0.7424\n",
            "Epoch 154/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8738 - accuracy: 0.7424\n",
            "Epoch 155/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8716 - accuracy: 0.7348\n",
            "Epoch 156/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8693 - accuracy: 0.7348\n",
            "Epoch 157/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8669 - accuracy: 0.7424\n",
            "Epoch 158/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8644 - accuracy: 0.7500\n",
            "Epoch 159/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8622 - accuracy: 0.7500\n",
            "Epoch 160/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8597 - accuracy: 0.7500\n",
            "Epoch 161/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8574 - accuracy: 0.7500\n",
            "Epoch 162/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8554 - accuracy: 0.7500\n",
            "Epoch 163/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8528 - accuracy: 0.7576\n",
            "Epoch 164/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8502 - accuracy: 0.7576\n",
            "Epoch 165/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8485 - accuracy: 0.7500\n",
            "Epoch 166/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8463 - accuracy: 0.7500\n",
            "Epoch 167/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8442 - accuracy: 0.7500\n",
            "Epoch 168/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8419 - accuracy: 0.7500\n",
            "Epoch 169/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8404 - accuracy: 0.7500\n",
            "Epoch 170/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8377 - accuracy: 0.7652\n",
            "Epoch 171/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8359 - accuracy: 0.7652\n",
            "Epoch 172/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8344 - accuracy: 0.7576\n",
            "Epoch 173/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8332 - accuracy: 0.7500\n",
            "Epoch 174/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8308 - accuracy: 0.7576\n",
            "Epoch 175/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8290 - accuracy: 0.7576\n",
            "Epoch 176/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8271 - accuracy: 0.7652\n",
            "Epoch 177/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8250 - accuracy: 0.7727\n",
            "Epoch 178/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8229 - accuracy: 0.7652\n",
            "Epoch 179/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8209 - accuracy: 0.7576\n",
            "Epoch 180/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8190 - accuracy: 0.7576\n",
            "Epoch 181/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8169 - accuracy: 0.7576\n",
            "Epoch 182/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8148 - accuracy: 0.7576\n",
            "Epoch 183/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8131 - accuracy: 0.7576\n",
            "Epoch 184/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8111 - accuracy: 0.7500\n",
            "Epoch 185/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8090 - accuracy: 0.7576\n",
            "Epoch 186/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8062 - accuracy: 0.7576\n",
            "Epoch 187/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8045 - accuracy: 0.7576\n",
            "Epoch 188/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8025 - accuracy: 0.7652\n",
            "Epoch 189/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8005 - accuracy: 0.7576\n",
            "Epoch 190/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7993 - accuracy: 0.7652\n",
            "Epoch 191/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7977 - accuracy: 0.7652\n",
            "Epoch 192/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7957 - accuracy: 0.7652\n",
            "Epoch 193/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7940 - accuracy: 0.7727\n",
            "Epoch 194/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7923 - accuracy: 0.7727\n",
            "Epoch 195/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7909 - accuracy: 0.7652\n",
            "Epoch 196/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7894 - accuracy: 0.7652\n",
            "Epoch 197/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7876 - accuracy: 0.7652\n",
            "Epoch 198/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.7652\n",
            "Epoch 199/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7838 - accuracy: 0.7652\n",
            "Epoch 200/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7822 - accuracy: 0.7652\n",
            "Epoch 201/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7802 - accuracy: 0.7727\n",
            "Epoch 202/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7782 - accuracy: 0.7727\n",
            "Epoch 203/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7764 - accuracy: 0.7727\n",
            "Epoch 204/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7742 - accuracy: 0.7727\n",
            "Epoch 205/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7725 - accuracy: 0.7652\n",
            "Epoch 206/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7707 - accuracy: 0.7652\n",
            "Epoch 207/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7688 - accuracy: 0.7652\n",
            "Epoch 208/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7673 - accuracy: 0.7652\n",
            "Epoch 209/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7655 - accuracy: 0.7652\n",
            "Epoch 210/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7638 - accuracy: 0.7652\n",
            "Epoch 211/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7621 - accuracy: 0.7727\n",
            "Epoch 212/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.7803\n",
            "Epoch 213/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 0.7803\n",
            "Epoch 214/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7577 - accuracy: 0.7803\n",
            "Epoch 215/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7560 - accuracy: 0.7803\n",
            "Epoch 216/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7542 - accuracy: 0.7803\n",
            "Epoch 217/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7532 - accuracy: 0.7727\n",
            "Epoch 218/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7512 - accuracy: 0.7727\n",
            "Epoch 219/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7496 - accuracy: 0.7727\n",
            "Epoch 220/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7485 - accuracy: 0.7727\n",
            "Epoch 221/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7469 - accuracy: 0.7803\n",
            "Epoch 222/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7455 - accuracy: 0.7879\n",
            "Epoch 223/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7442 - accuracy: 0.7879\n",
            "Epoch 224/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7431 - accuracy: 0.7803\n",
            "Epoch 225/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7412 - accuracy: 0.7879\n",
            "Epoch 226/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7392 - accuracy: 0.7879\n",
            "Epoch 227/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7382 - accuracy: 0.7803\n",
            "Epoch 228/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7363 - accuracy: 0.7803\n",
            "Epoch 229/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.7803\n",
            "Epoch 230/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7331 - accuracy: 0.7652\n",
            "Epoch 231/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7318 - accuracy: 0.7652\n",
            "Epoch 232/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7301 - accuracy: 0.7727\n",
            "Epoch 233/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7283 - accuracy: 0.7652\n",
            "Epoch 234/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7270 - accuracy: 0.7576\n",
            "Epoch 235/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7256 - accuracy: 0.7500\n",
            "Epoch 236/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7244 - accuracy: 0.7652\n",
            "Epoch 237/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7225 - accuracy: 0.7727\n",
            "Epoch 238/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7209 - accuracy: 0.7727\n",
            "Epoch 239/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7194 - accuracy: 0.7727\n",
            "Epoch 240/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7182 - accuracy: 0.7803\n",
            "Epoch 241/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7167 - accuracy: 0.7879\n",
            "Epoch 242/450\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.7154 - accuracy: 0.7879\n",
            "Epoch 243/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7147 - accuracy: 0.7955\n",
            "Epoch 244/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7129 - accuracy: 0.8030\n",
            "Epoch 245/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7116 - accuracy: 0.8030\n",
            "Epoch 246/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7103 - accuracy: 0.8030\n",
            "Epoch 247/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7090 - accuracy: 0.7955\n",
            "Epoch 248/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7076 - accuracy: 0.7955\n",
            "Epoch 249/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.7803\n",
            "Epoch 250/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7043 - accuracy: 0.7803\n",
            "Epoch 251/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7036 - accuracy: 0.7879\n",
            "Epoch 252/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7020 - accuracy: 0.8030\n",
            "Epoch 253/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7008 - accuracy: 0.8106\n",
            "Epoch 254/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6993 - accuracy: 0.8106\n",
            "Epoch 255/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6981 - accuracy: 0.8106\n",
            "Epoch 256/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.8106\n",
            "Epoch 257/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.8106\n",
            "Epoch 258/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.8106\n",
            "Epoch 259/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.8106\n",
            "Epoch 260/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.8106\n",
            "Epoch 261/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6900 - accuracy: 0.7955\n",
            "Epoch 262/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.7879\n",
            "Epoch 263/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.7879\n",
            "Epoch 264/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6874 - accuracy: 0.7879\n",
            "Epoch 265/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6865 - accuracy: 0.7803\n",
            "Epoch 266/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6855 - accuracy: 0.7803\n",
            "Epoch 267/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.7879\n",
            "Epoch 268/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.7879\n",
            "Epoch 269/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.8030\n",
            "Epoch 270/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6797 - accuracy: 0.8030\n",
            "Epoch 271/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.8106\n",
            "Epoch 272/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.8106\n",
            "Epoch 273/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.8106\n",
            "Epoch 274/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.8106\n",
            "Epoch 275/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.8106\n",
            "Epoch 276/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.8106\n",
            "Epoch 277/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.8106\n",
            "Epoch 278/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6700 - accuracy: 0.8106\n",
            "Epoch 279/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.8106\n",
            "Epoch 280/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.8258\n",
            "Epoch 281/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.8030\n",
            "Epoch 282/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6648 - accuracy: 0.8258\n",
            "Epoch 283/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6637 - accuracy: 0.8182\n",
            "Epoch 284/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.8030\n",
            "Epoch 285/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6619 - accuracy: 0.8030\n",
            "Epoch 286/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.8030\n",
            "Epoch 287/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6596 - accuracy: 0.8106\n",
            "Epoch 288/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.8106\n",
            "Epoch 289/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6572 - accuracy: 0.8182\n",
            "Epoch 290/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.8258\n",
            "Epoch 291/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.8258\n",
            "Epoch 292/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.8258\n",
            "Epoch 293/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.8258\n",
            "Epoch 294/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.8258\n",
            "Epoch 295/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6505 - accuracy: 0.8258\n",
            "Epoch 296/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.8258\n",
            "Epoch 297/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6482 - accuracy: 0.8258\n",
            "Epoch 298/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.8258\n",
            "Epoch 299/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6457 - accuracy: 0.8333\n",
            "Epoch 300/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6448 - accuracy: 0.8182\n",
            "Epoch 301/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6445 - accuracy: 0.8182\n",
            "Epoch 302/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6436 - accuracy: 0.8258\n",
            "Epoch 303/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.8258\n",
            "Epoch 304/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.8258\n",
            "Epoch 305/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.8182\n",
            "Epoch 306/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.8182\n",
            "Epoch 307/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.8182\n",
            "Epoch 308/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.8106\n",
            "Epoch 309/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.8182\n",
            "Epoch 310/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.8182\n",
            "Epoch 311/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.8258\n",
            "Epoch 312/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.8258\n",
            "Epoch 313/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.8258\n",
            "Epoch 314/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.8258\n",
            "Epoch 315/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6294 - accuracy: 0.8409\n",
            "Epoch 316/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6284 - accuracy: 0.8409\n",
            "Epoch 317/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6272 - accuracy: 0.8409\n",
            "Epoch 318/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6261 - accuracy: 0.8485\n",
            "Epoch 319/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.8485\n",
            "Epoch 320/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.8485\n",
            "Epoch 321/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.8485\n",
            "Epoch 322/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6223 - accuracy: 0.8485\n",
            "Epoch 323/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.8485\n",
            "Epoch 324/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.8485\n",
            "Epoch 325/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.8485\n",
            "Epoch 326/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6184 - accuracy: 0.8485\n",
            "Epoch 327/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.8409\n",
            "Epoch 328/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6161 - accuracy: 0.8409\n",
            "Epoch 329/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.8409\n",
            "Epoch 330/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.8333\n",
            "Epoch 331/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.8409\n",
            "Epoch 332/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6125 - accuracy: 0.8409\n",
            "Epoch 333/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6119 - accuracy: 0.8333\n",
            "Epoch 334/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6107 - accuracy: 0.8333\n",
            "Epoch 335/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6099 - accuracy: 0.8258\n",
            "Epoch 336/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6090 - accuracy: 0.8258\n",
            "Epoch 337/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6079 - accuracy: 0.8333\n",
            "Epoch 338/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.8333\n",
            "Epoch 339/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6061 - accuracy: 0.8333\n",
            "Epoch 340/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.8485\n",
            "Epoch 341/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.8485\n",
            "Epoch 342/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6035 - accuracy: 0.8561\n",
            "Epoch 343/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6024 - accuracy: 0.8561\n",
            "Epoch 344/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.8561\n",
            "Epoch 345/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6004 - accuracy: 0.8485\n",
            "Epoch 346/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5995 - accuracy: 0.8485\n",
            "Epoch 347/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.8485\n",
            "Epoch 348/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5977 - accuracy: 0.8485\n",
            "Epoch 349/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.8485\n",
            "Epoch 350/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5957 - accuracy: 0.8409\n",
            "Epoch 351/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.8409\n",
            "Epoch 352/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.8485\n",
            "Epoch 353/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5932 - accuracy: 0.8636\n",
            "Epoch 354/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.8485\n",
            "Epoch 355/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.8561\n",
            "Epoch 356/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.8561\n",
            "Epoch 357/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.8561\n",
            "Epoch 358/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.8561\n",
            "Epoch 359/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5881 - accuracy: 0.8409\n",
            "Epoch 360/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5877 - accuracy: 0.8485\n",
            "Epoch 361/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5870 - accuracy: 0.8485\n",
            "Epoch 362/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.8485\n",
            "Epoch 363/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5858 - accuracy: 0.8485\n",
            "Epoch 364/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5845 - accuracy: 0.8485\n",
            "Epoch 365/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5835 - accuracy: 0.8409\n",
            "Epoch 366/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.8485\n",
            "Epoch 367/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5819 - accuracy: 0.8485\n",
            "Epoch 368/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.8485\n",
            "Epoch 369/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5803 - accuracy: 0.8561\n",
            "Epoch 370/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.8561\n",
            "Epoch 371/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5787 - accuracy: 0.8485\n",
            "Epoch 372/450\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5777 - accuracy: 0.8485\n",
            "Epoch 373/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.8561\n",
            "Epoch 374/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.8561\n",
            "Epoch 375/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.8636\n",
            "Epoch 376/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.8636\n",
            "Epoch 377/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.8561\n",
            "Epoch 378/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.8561\n",
            "Epoch 379/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.8561\n",
            "Epoch 380/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.8561\n",
            "Epoch 381/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.8485\n",
            "Epoch 382/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.8485\n",
            "Epoch 383/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.8561\n",
            "Epoch 384/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.8561\n",
            "Epoch 385/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.8485\n",
            "Epoch 386/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.8485\n",
            "Epoch 387/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.8485\n",
            "Epoch 388/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.8485\n",
            "Epoch 389/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.8485\n",
            "Epoch 390/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.8485\n",
            "Epoch 391/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.8561\n",
            "Epoch 392/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.8409\n",
            "Epoch 393/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.8333\n",
            "Epoch 394/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.8409\n",
            "Epoch 395/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.8409\n",
            "Epoch 396/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.8333\n",
            "Epoch 397/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.8333\n",
            "Epoch 398/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.8409\n",
            "Epoch 399/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.8409\n",
            "Epoch 400/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.8409\n",
            "Epoch 401/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.8409\n",
            "Epoch 402/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.8409\n",
            "Epoch 403/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.8409\n",
            "Epoch 404/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.8409\n",
            "Epoch 405/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.8333\n",
            "Epoch 406/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.8409\n",
            "Epoch 407/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.8409\n",
            "Epoch 408/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.8409\n",
            "Epoch 409/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.8561\n",
            "Epoch 410/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.8561\n",
            "Epoch 411/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.8561\n",
            "Epoch 412/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.8561\n",
            "Epoch 413/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.8485\n",
            "Epoch 414/450\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.8485\n",
            "Epoch 415/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.8485\n",
            "Epoch 416/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.8485\n",
            "Epoch 417/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.8561\n",
            "Epoch 418/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.8712\n",
            "Epoch 419/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.8712\n",
            "Epoch 420/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.8636\n",
            "Epoch 421/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.8636\n",
            "Epoch 422/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.8636\n",
            "Epoch 423/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.8636\n",
            "Epoch 424/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.8636\n",
            "Epoch 425/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.8561\n",
            "Epoch 426/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.8561\n",
            "Epoch 427/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.8636\n",
            "Epoch 428/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.8561\n",
            "Epoch 429/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.8561\n",
            "Epoch 430/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.8636\n",
            "Epoch 431/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.8636\n",
            "Epoch 432/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.8712\n",
            "Epoch 433/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.8712\n",
            "Epoch 434/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.8712\n",
            "Epoch 435/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.8561\n",
            "Epoch 436/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.8485\n",
            "Epoch 437/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.8485\n",
            "Epoch 438/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.8485\n",
            "Epoch 439/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.8409\n",
            "Epoch 440/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.8485\n",
            "Epoch 441/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.8485\n",
            "Epoch 442/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.8485\n",
            "Epoch 443/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.8485\n",
            "Epoch 444/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.8485\n",
            "Epoch 445/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.8485\n",
            "Epoch 446/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.8561\n",
            "Epoch 447/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.8561\n",
            "Epoch 448/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.8712\n",
            "Epoch 449/450\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.8712\n",
            "Epoch 450/450\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.8712\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d40d94925f0>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(5 , input_shape=(50,) , activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam() ,\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=\"accuracy\")\n",
        "\n",
        "model.fit(X_train_avg , Y_train_OneHot , epochs=450)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tfHOjucoS0M"
      },
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGqxwQVHgJcd",
        "outputId": "309783ef-f955-43f8-9c42-d729876ec5d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.0130675 , -0.16553   , -0.59810925, -0.49592   ,  0.59033   ,\n",
              "        0.22704   , -0.32189   , -0.12010185,  0.222575  ,  0.11118689,\n",
              "       -0.2046    ,  0.44136   ,  0.3844075 , -0.02622   ,  0.9114375 ,\n",
              "        0.10927853,  0.3785775 ,  0.2093365 , -0.343201  , -0.52781   ,\n",
              "       -0.26966   , -0.03548105,  1.1430625 ,  0.5685    ,  0.60376   ,\n",
              "       -1.471715  , -0.5846825 ,  0.28988625,  1.222875  , -0.723584  ,\n",
              "        2.4087    ,  0.490035  , -0.215285  ,  0.00643   , -0.49763225,\n",
              "       -0.0170525 , -0.1293525 ,  0.191065  ,  0.431245  ,  0.0333175 ,\n",
              "       -0.24118657, -0.057487  ,  0.20188   ,  0.715315  ,  1.0069615 ,\n",
              "        0.3474925 , -0.2268875 , -0.5768925 ,  0.114906  ,  0.533535  ])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_test = \"i hate eating fish\"\n",
        "\n",
        "# extracting features\n",
        "my_test_avg = sentence_to_average(my_test)\n",
        "my_test_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "G9kzdty3rTHd",
        "outputId": "77e14ab6-e48d-4882-dc3d-6507685c58af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ðŸ½'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_test_avg = np.array([my_test_avg])\n",
        "result = model.predict(my_test_avg)\n",
        "y_pred = np.argmax(result)\n",
        "label_to_emoji(y_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
